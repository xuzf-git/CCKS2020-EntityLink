{
 "cells": [
  {
   "source": [
    "<h1 style=\"text-align:center\">基于 BiLSTM-Attention 的实体消歧系统示例</h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import utils\n",
    "from data_process import *\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\xuzf\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.745 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# vocab 包含 vocab[\"w2i\"]: word2idx、vocab[\"i2w\"]：\n",
    "matrix = np.load('./data/pretrain_data/matrix.npy')\n",
    "with open('./data/pretrain_data/vocab.json', 'r', encoding='utf8') as f:\n",
    "    jsonstr = ''.join(f.readlines())\n",
    "    vocab = json.loads(jsonstr)\n",
    "\n",
    "# 生成 mention 的候选实体集合\n",
    "if os.path.exists('./data/generated/cand.json'):\n",
    "    with open('./data/generated/cand.json', 'r', encoding='utf8') as f:\n",
    "        jsonstr = ''.join(f.readlines())\n",
    "        cand_dic = json.loads(jsonstr)\n",
    "    with open('./data/generated/entity.json', 'r', encoding='utf8') as f:\n",
    "        jsonstr = ''.join(f.readlines())\n",
    "        ent_dic = json.loads(jsonstr)\n",
    "else:\n",
    "    cand_dic, ent_dic = GenerateCand('kb.json')\n",
    "\n",
    "# 实例化编码类\n",
    "data_encoder = DataEncoder(vocab[\"w2i\"], utils.type2label)\n",
    "\n",
    "# 实例化模型\n",
    "model = Model(matrix, utils.param)\n",
    "model.load_state_dict(torch.load('./weight/ckpt_best_2.pth')['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_line = {\n",
    "    \"text_id\": \"3\",\n",
    "    \"text\": \"《绿皮书》托尼·利普和唐博士，配上这首歌，网友：这种情愫有点嗲\",\n",
    "    \"mention_data\": [\n",
    "        {\n",
    "            \"mention\": \"《绿皮书》\",\n",
    "            \"offset\": \"0\"\n",
    "        },\n",
    "        {\n",
    "            \"mention\": \"托尼·利普\",\n",
    "            \"offset\": \"5\"\n",
    "        },\n",
    "        {\n",
    "            \"mention\": \"唐博士\",\n",
    "            \"offset\": \"10\"\n",
    "        },\n",
    "        {\n",
    "            \"mention\": \"歌\",\n",
    "            \"offset\": \"18\"\n",
    "        },\n",
    "        {\n",
    "            \"mention\": \"情愫\",\n",
    "            \"offset\": \"25\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Encode ./data/generated/predict_data.txt: 28it [00:00, 718.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jsonstr = json.dumps(predict_line, ensure_ascii=False)\n",
    "with open(\"./data/basic_data/predict.json\", 'w', encoding='utf-8') as jsonfile:\n",
    "    jsonfile.write(jsonstr)\n",
    "\n",
    "# 生成预测的文本数据\n",
    "GeneratePairwaiseSample('predict.json', cand_dic, ent_dic, is_train=False)\n",
    "\n",
    "# 数据编码\n",
    "data_encoder.data_encode(\"./data/generated/predict_data.txt\", is_train=False)\n",
    "\n",
    "# 构建数据集加载接口\n",
    "predict_set = DataSet(\"./data/generated/predict.csv\", is_train=False)\n",
    "\n",
    "# dataloader\n",
    "test_loader = DATA.DataLoader(predict_set,  batch_size=8, collate_fn=utils.collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果\n",
    "result = {}\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    id_list, query, offset, cand_desc, seq_len = test_data\n",
    "    # forward\n",
    "    pre_label, pre_type = model.predict(query, offset, cand_desc, seq_len)\n",
    "    # 记录预测结果\n",
    "    result = utils.record(result, id_list, torch.softmax(pre_label, dim=-1), pre_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "文本:\t 《绿皮书》托尼·利普和唐博士，配上这首歌，网友：这种情愫有点嗲 \n\n实体:\t 《绿皮书》\n类型:\t Work\n描述:\t 外文名:Green Book;摘要:《绿皮书》是由彼得·法拉利执导，维果·莫特森、马赫沙拉·阿里主演的剧情片，于2018年9月11日在多伦多国际电影节首映；2019年3月1日在中国内地上映。;制片地区:美国;编剧:Brian Currie、彼得·法拉利、尼克·维勒欧嘉;片长:130分钟;对白语言:英语;主演:维果·莫特森，马赫沙拉·阿里;导演:彼得·法拉利;中文名:绿皮书;发行公司:环球影业;上映时间:2018年9月11日(多伦多国际电影节)、2019年3月1日（中国内地）;类型:剧情片;义项描述:美国2018年彼得·法拉利执导电影;主要奖项:第91届奥斯卡金像奖最佳影片;色彩:彩色;其它译名:绿书、绿簿旅友、幸福绿皮书;\n\n\n实体:\t 托尼·利普\n类型:\t Other\n\n\n实体:\t 唐博士\n类型:\t Other\n\n\n实体:\t 歌\n类型:\t VirtualThings\n描述:\t 外文名:THE SONG;摘要:歌，为日本漫画创作团体CLAMP所创作的作品《魔卡少女樱》动画原创的卡牌。;出处:《魔卡少女樱》;中文名:歌;义项描述:《魔卡少女樱》中的卡牌;持有者:木之本樱;\n\n\n实体:\t 情愫\n类型:\t Work\n描述:\t 摘要:《情愫》是2011年云南人民出版社出版出版的图书，作者是陈强。;出版社:云南人民出版社出版;作者:陈强;义项描述:陈强诗集;出版时间:2011年11月;书名:情愫;标签:艺术书籍、出版物、书籍;\n\n\n"
     ]
    }
   ],
   "source": [
    "# 处理预测结果，生成打印信息\n",
    "data = [predict_line]\n",
    "\n",
    "for i, line in enumerate(data):\n",
    "    res_line = result[line['text_id']]\n",
    "    mention_data = line[\"mention_data\"]\n",
    "    for mid, item in enumerate(line[\"mention_data\"]):\n",
    "        item['pre_id'] = res_line[str(mid)]['pre_id']\n",
    "        pre_type_id = res_line[str(mid)]['pre_type'].argmax().item()\n",
    "        item['pre_type'] = utils.lable2type[pre_type_id]\n",
    "        if item['pre_id'] != 'NIL':\n",
    "            item[\"pre_desc\"] = ent_dic[item['pre_id']]['ent_desc']\n",
    "            item['pre_type'] = ent_dic[item['pre_id']]['type']\n",
    "        mention_data[mid] = item\n",
    "    data[i]['mention_data'] = mention_data\n",
    "# 打印结果\n",
    "for i in data:\n",
    "    print(\"文本:\\t\", i['text'], '\\n')\n",
    "    for j in i['mention_data']:\n",
    "        print(\"实体:\\t\", j['mention'])\n",
    "        print(\"类型:\\t\", j['pre_type'])\n",
    "        if j['pre_id'] != 'NIL':\n",
    "            print('描述:\\t', j['pre_desc'])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f2e31668ff856660fd38285f884f98268431b14451c4bab186f462167deaa538"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}